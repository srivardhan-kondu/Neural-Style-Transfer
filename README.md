
# ğŸ¨ Neural Style Transfer

Welcome to the **Neural Style Transfer** project! This tool allows you to merge the content of one image and the artistic style of another to create stunning mixed images. ğŸ–¼ï¸âœ¨

## ğŸ“ Table of Contents

- [ğŸŒŸ Overview](#-overview)
- [âš™ï¸ Installation](#-installation)
- [ğŸš€ Usage](#-usage)
- [ğŸ” Code Explanation](#-code-explanation)
- [ğŸ“· Example](#-example)
- [ğŸ‰ Results](#-results)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)

## ğŸŒŸ Overview

Neural Style Transfer (NST) combines two images:
- **Content Image** ğŸ–¼ï¸: The image with the main structure and objects.
- **Style Image** ğŸ¨: The image from which artistic textures and patterns are borrowed.

This project uses a TensorFlow Hub model to achieve the mixing, creating an image with the **content** of one and the **style** of the other. ğŸ§‘â€ğŸ¨

## âš™ï¸ Installation

1. Clone the repository:  
   ```bash
   git clone https://github.com/srivardhan-kondu/Neural-Style-Transfer.git
   cd Neural-Style-Transfer
   ```

2. Install the required dependencies:  
   ```bash
   pip install tensorflow tensorflow_hub matplotlib numpy opencv-python
   ```

3. Make sure you have your **content** and **style** images in the project directory.

## ğŸš€ Usage

To generate a stylized image, follow these steps:

1. Place your **content image** and **style image** in the project directory.
2. Run the following command:  
   ```bash
   python neural_style_transfer.py
   ```

3. The generated image will be saved as `generated_img.jpg` in the directory.

### ğŸ–¼ï¸ Input Images
- **Content Image**: `input.jpg`
- **Style Image**: `style.jpg`

### ğŸ–¼ï¸ Output Image
- The generated image will be saved as `generated_img.jpg`.

## ğŸ” Code Explanation

### Key Sections of the Code:

1. **Importing Libraries** ğŸ“š:
    ```python
    import tensorflow_hub as hub
    import tensorflow as tf
    from matplotlib import pyplot as plt
    import numpy as np
    import cv2
    ```

2. **Loading the Pre-Trained Model** ğŸš€:
    The model for stylization is loaded from TensorFlow Hub:
    ```python
    model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')
    ```

3. **Image Preprocessing** ğŸ–¼ï¸:
    This helper function loads and preprocesses images for the model:
    ```python
    def load_image(img_path):
        img = tf.io.read_file(img_path)
        img = tf.image.decode_image(img, channels=3)
        img = tf.image.convert_image_dtype(img, tf.float32)
        img = img[tf.newaxis, :]
        return img
    ```

4. **Performing Style Transfer** ğŸ¨:
    The model applies the style of the style image to the content image:
    ```python
    stylized_image = model(tf.constant(content_image), tf.constant(style_image))[0]
    ```

5. **Saving the Generated Image** ğŸ’¾:
    Finally, the generated image is saved using OpenCV:
    ```python
    cv2.imwrite('generated_img.jpg', cv2.cvtColor(np.squeeze(stylized_image)*255, cv2.COLOR_BGR2RGB))
    ```

## ğŸ“· Example

### ğŸ¨ Content Image:
![Content Image](./input.png)

### ğŸ–Œï¸ Style Image:
![Style Image](./style.png)

### ğŸ§‘â€ğŸ¨ Generated Image:
![Generated Image](./generated_image.png)

---

## ğŸ‰ Results

After running the code, you will get:

1. The **style image** and **content image** displayed.
2. The **generated image** with content and style merged.
3. The output saved as `generated_img.jpg`.

### ğŸ“¥ Download the Generated Image
Once processed, you can [download the generated image](generated_img.jpg). ğŸ¨

## ğŸ¤ Contributing

We welcome contributions! If you have improvements or bug fixes, feel free to open a pull request or issue.

1. Fork this repository.
2. Create a new branch with your changes.
3. Submit a pull request for review.

## ğŸ“„ License

This project is licensed under the MIT License. See the `LICENSE` file for more details.

---

ğŸ“© **Contact**: Reach out via [srivardhan.kondu@gmail.com](mailto:srivardhan.kondu@gmail.com) if you have any questions or suggestions.
